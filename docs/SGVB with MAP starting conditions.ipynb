{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGVB with MAP starting conditions\n",
    "\n",
    "In which we try to speed up stochastic inference by starting with a MAP (Laplace) estimate.\n",
    "\n",
    "Note, we zero out the covariances between variables, so that the starting covariance is block-diagonal, to make the procedure more stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptvi import *\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('precision', 2)\n",
    "plt.rcParams['figure.figsize'] = [12, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_seed, algo_seed = 123, 123  # change and rerun all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "γ0, η0, σ0, ρ0 = 0., 2., 1.5, 0.92\n",
    "true_params = {'γ': γ0, 'η': η0, 'σ': σ0, 'ρ': ρ0}\n",
    "torch.manual_seed(data_seed)\n",
    "y, z = LocalLevelModel(input_length=100).simulate(**true_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximate inference with MAP starting conditions\n",
    "\n",
    "One of the reasons this is fast is we can relax the stopping condition a bit, because we know it is already close to a reasonable answer and we can accept a higher probability of an early stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――\n",
      "MAP inference with L-BGFS: Local level model\n",
      "――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――\n",
      "       0. ll = -1106.6174\n",
      "       1. ll = -368.8922\n",
      "       2. ll = -259.3571\n",
      "       3. ll = -251.2169\n",
      "       4. ll = -251.1165\n",
      "       5. ll = -251.1164\n",
      "Convergence criterion met.\n",
      "       5. ll = -251.1164\n",
      "Completed 6 iterations in 0.16s @ 36.70 i/s.\n",
      "――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――\n",
      "――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――\n",
      "Structured SGVB Inference\n",
      "\n",
      "Local level model:\n",
      "  - input length 100\n",
      "  - Stochastic entropy term with M=1;\n",
      "  - Stop on no improvement (skip=1, patience=50, min_steps=100, ε=0.01, α=0.1)\n",
      "  - Adadelta optimizer with param groups:\n",
      "    group 0. lr=1.0, rho=0.9, eps=1e-06, weight_decay=0\n",
      "\n",
      "Displayed loss is smoothed with λ=0.1\n",
      "――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――\n",
      "       0. smoothed elbo_hat =     -261.94\n",
      "       1. smoothed elbo_hat =     -262.38\n",
      "       2. smoothed elbo_hat =     -262.70\n",
      "       4. smoothed elbo_hat =     -263.08\n",
      "       8. smoothed elbo_hat =     -265.14\n",
      "      16. smoothed elbo_hat =     -267.93\n",
      "      32. smoothed elbo_hat =     -277.03\n",
      "      64. smoothed elbo_hat =     -288.03\n",
      "     128. smoothed elbo_hat =     -275.77\n",
      "     256. smoothed elbo_hat =     -273.53\n",
      "     512. smoothed elbo_hat =     -273.95\n",
      "    1024. smoothed elbo_hat =     -267.12\n",
      "    2048. smoothed elbo_hat =     -262.47\n",
      "    4096. smoothed elbo_hat =     -260.61\n",
      "    8192. smoothed elbo_hat =     -259.28\n",
      "   16384. smoothed elbo_hat =     -257.34\n",
      "   32768. smoothed elbo_hat =     -261.63\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(algo_seed)\n",
    "model = LocalLevelModel(input_length=100, stochastic_entropy=True, quiet=False, num_draws=1)\n",
    "model.u.data, model.L.data = model.initial_conditions(y)\n",
    "model.stop_heur = NoImprovementStoppingHeuristic(patience=50) # weak\n",
    "fit = model.training_loop(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.plot_latent(z=z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.plot_global_marginals(**true_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.plot_pred_ci(N=500, α=.1, true_y=y, fc_steps=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison: starting at $u=0, L=I$\n",
    "\n",
    "### With weak stopping rule\n",
    "\n",
    "Matches the stopping rule we used in the hybrid procedure, above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(algo_seed)\n",
    "model = LocalLevelModel(input_length=100, stochastic_entropy=True, quiet=False)\n",
    "model.stop_heur = NoImprovementStoppingHeuristic(patience=50)  # weak\n",
    "fit = model.training_loop(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.plot_latent(z=z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.plot_global_marginals(**true_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fit.plot_pred_ci(N=500, α=.1, true_y=y, fc_steps=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With strong stopping rule\n",
    "\n",
    "This is currently the default stopping rule in my codebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(algo_seed)\n",
    "model = LocalLevelModel(input_length=100, stochastic_entropy=True, quiet=False)\n",
    "fit = model.training_loop(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.plot_latent(z=z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.plot_global_marginals(**true_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fit.plot_pred_ci(N=500, α=.1, true_y=y, fc_steps=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
